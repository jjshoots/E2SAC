# env type
env_name: 'AntPyBulletEnv-v0'
# env_name: 'HopperPyBulletEnv-v0'
# env_name: 'Walker2DPyBulletEnv-v0'
# env_name: 'HalfCheetahPyBulletEnv-v0'

# size of suboptimal policy
sub_size: '_smol'

# training params
buffer_size: 300000
buffer_size_debug: 100
batch_size: 256
total_steps: 1000000
repeats_per_buffer: 1
critic_update_multiplier: 1
actor_update_multiplier: 1
discount_factor: 0.98
learning_rate: 0.0004

# exploration settings
exploration_steps: 0

# algorithm specifics
supervision_lambda: 1.0
confidence_lambda: 200.0
use_entropy: true
target_entropy: null
n_var_samples: 16

# eval settings
eval_num_episodes: 10
eval_steps_ratio: 20000

# display settings
display: false

# wingman required params
debug: false

weights_directory: 'weights'
version_number: null
mark_number: 0

increment: false
epoch_interval: 1
batch_interval: -1
max_skips: 5
greater_than: 0.0

wandb: false
wandb_name: ''
wandb_notes: ''
wandb_id: ''
wandb_entity: 'jjshoots'
wandb_project: 'ccge_dm_control'
